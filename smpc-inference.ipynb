{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMPC idea for model inference\n",
    "\n",
    "This notebook shows the overall flow of model inferencing with SMPC.  \n",
    "Assumptions made:  \n",
    "1. Two workers will be performing the computation.  Pygrid and the data holder's device will not participate in any computation, they are just responsible for data splitting and sending to the workers.  \n",
    "2. No worker will get a full copy of unencrypted user data nor the model weights. Each of them will get only an encrypted tensor which could assemble the original data only when the tensors from different devices are combined together. \n",
    "3. Both workers will be able to get the basic model architecture and initialize it with random weights (i.e. Assume that only the weights are sensitive but not the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this if needed\n",
    "#!pip install crypten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import torch as th\n",
    "import collections\n",
    "\n",
    "crypten.init()\n",
    "th.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define different hosts participating in SMPC\n",
    "WORKER1 = 0\n",
    "WORKER2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters (this will be )\n",
    "n_users = 10\n",
    "song_features = 10\n",
    "bs = 64  # batch_size\n",
    "lr = 5e-4\n",
    "embedding_size = 50\n",
    "layer_sizes = [(embedding_size + song_features, 150), (150, 300), (300, 200), (200, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 -- User data split\n",
    "\n",
    "The following are assumed to be run on user device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User data generation -- assume the data below are from the user device\n",
    "user = th.zeros((n_users,))\n",
    "user[0] = 1\n",
    "user = th.reshape(user,(1,-1))\n",
    "features = th.tensor([0.233021,1.320897,0.128987,0.613270,0.256593,-0.377054,0.104040,0.394174,-0.239261,-0.550271])\n",
    "features = th.reshape(features,(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from crypten import mpc\n",
    "import crypten.communicator as comm \n",
    "@mpc.run_multiprocess(world_size=2) #the world_size here corresponds to how many workers running the SMPC\n",
    "def data_separation():\n",
    "    usertensor = crypten.cryptensor(user)\n",
    "    featuretensor = crypten.cryptensor(features)\n",
    "    rank = comm.get().get_rank()\n",
    "    #crypten.print(f\"\\nRank {rank}:\\n {usertensor}\\n\", in_order=True)\n",
    "    crypten.save(usertensor, f\"data/user{rank}.pth\") \n",
    "    crypten.save(featuretensor,f\"data/feature{rank}.pth\")\n",
    "data_separation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 -- Model split\n",
    "\n",
    "The following are assumed to be run on pygrid / parcel (#TODO: check if it is possible to obtain the encrypted split weights directly in parcel and save to pygrid?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: how to save this model architecture in pygrid and send it to both workers (unencrypted, only random weights)\n",
    "#NOTE THAT the model definition is slightly different from the one used in pygrid mobile, but should still work \n",
    "#since the shape of model weights remain the same (i.e. we could still copy the weights from the trained model in pygrid to here)\n",
    "class EmbeddingNet(th.nn.Module):  \n",
    "    \"\"\"\n",
    "    Simple model with method for loss and hand-written backprop.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.embedlayer = th.nn.Linear(n_users, embedding_size) #chagned\n",
    "        self.fc1 = th.nn.Linear(layer_sizes[0][0], layer_sizes[0][1])\n",
    "        self.fc2 = th.nn.Linear(layer_sizes[1][0], layer_sizes[1][1])\n",
    "        self.fc3 = th.nn.Linear(layer_sizes[2][0], layer_sizes[2][1])\n",
    "        self.fc4 = th.nn.Linear(layer_sizes[3][0], layer_sizes[3][1])\n",
    "\n",
    "    def forward(self, users,features):\n",
    "        \"\"\"\n",
    "        users: a one-hot tensor of size (n_users,) representing the user.\n",
    "        features: 10d vector using spotify-provided feature values\n",
    "        x: a 60d dummy vector required from user\n",
    "        \"\"\"\n",
    "        out = self.embedlayer(users)\n",
    "        out = th.cat((out,features),dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = th.nn.functional.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = th.nn.functional.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = th.nn.functional.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        out = th.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a dummy model with random weights\n",
    "crypten.common.serial.register_safe_class(EmbeddingNet)\n",
    "local_model = EmbeddingNet()\n",
    "th.save(local_model,\"data/model_random.pth\")\n",
    "#Save trained model : Weights are dummy for the purpose of this demo\n",
    "trained_model = EmbeddingNet()\n",
    "sd = trained_model.state_dict()\n",
    "for layer in sd:\n",
    "    sd[layer] = th.ones(sd[layer].size())\n",
    "trained_model.load_state_dict(sd)\n",
    "th.save(trained_model,\"data/model_trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hinnes/projects/CrypTen/crypten/nn/onnx_converter.py:164: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  param = torch.from_numpy(numpy_helper.to_array(node))\n",
      "/home/hinnes/projects/CrypTen/crypten/nn/onnx_converter.py:164: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  param = torch.from_numpy(numpy_helper.to_array(node))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully encrypted:Model successfully encrypted:  TrueTrue\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@mpc.run_multiprocess(world_size=2)\n",
    "def model_split():\n",
    "    #Load the model\n",
    "    plaintext_model = th.load('data/model_trained.pth')\n",
    "    \n",
    "    #Construct a CrypTen network with the trained model and dummy_input\n",
    "    dummy_input = th.empty((1,10,)) ,th.empty((1,10,))\n",
    "    private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
    "    \n",
    "    #3. Encrypt the CrypTen network \n",
    "    private_model.encrypt(src=0)\n",
    "    rank = comm.get().get_rank()\n",
    "\n",
    "    crypten.save(private_model.state_dict(), f\"data/modelweights{rank}.pth\") \n",
    "\n",
    "    # #Check that model is encrypted:\n",
    "    print(\"Model successfully encrypted:\", private_model.encrypted)\n",
    "\n",
    "model_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Run the SMPC inferencing\n",
    "\n",
    "The following is to model two workers simply by two processes existing in a single machine. I have yet to determine how this could be done in multiple machines (hopefully should be straightforward.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor encrypted: True\n",
      "Decrypted data: tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "Tensor encrypted: True\n",
      "Decrypted data: tensor([[ 0.2330,  1.3209,  0.1290,  0.6133,  0.2566, -0.3770,  0.1040,  0.3942,\n",
      "         -0.2393, -0.5503]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hinnes/projects/CrypTen/crypten/nn/onnx_converter.py:164: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  param = torch.from_numpy(numpy_helper.to_array(node))\n",
      "/home/hinnes/projects/CrypTen/crypten/nn/onnx_converter.py:164: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  param = torch.from_numpy(numpy_helper.to_array(node))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.8450e+09]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm data ok\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def model_inference():\n",
    "    #1. Combine user data \n",
    "    user0 = crypten.load_from_party(\"data/user0.pth\",encrypted=True,src=WORKER1)\n",
    "    user1 = crypten.load_from_party(\"data/user1.pth\",encrypted=True,src=WORKER2)\n",
    "    user = (user0+user1)\n",
    "    crypten.print(\"Tensor encrypted:\", crypten.is_encrypted_tensor(user)) \n",
    "    crypten.print(\"Decrypted data:\",user.get_plain_text())\n",
    "    feature0 = crypten.load_from_party(\"data/feature0.pth\",encrypted=True,src=WORKER1)\n",
    "    feature1 = crypten.load_from_party(\"data/feature1.pth\",encrypted=True,src=WORKER2)\n",
    "    feature = (feature0+feature1)\n",
    "    crypten.print(\"Tensor encrypted:\", crypten.is_encrypted_tensor(feature)) \n",
    "    crypten.print(\"Decrypted data:\",feature.get_plain_text())\n",
    "    #2. load basic model\n",
    "    plaintext_model = th.load('data/model_random.pth') #use of load method instead of load_from_party: meaning that both process should have a copy of the document.\n",
    "    dummy_input = th.empty((1,10,)), th.empty((1,10,))\n",
    "    private_model = crypten.nn.from_pytorch(plaintext_model, dummy_input)\n",
    "    private_model.encrypt(src=WORKER1) #Actually the src is not important, weights are just dummy\n",
    "    #3. load and combine model weights\n",
    "    w1 = crypten.load_from_party(\"data/modelweights0.pth\",encrypted=True,src=WORKER1)\n",
    "    w2 = crypten.load_from_party(\"data/modelweights1.pth\",encrypted=True,src=WORKER2)\n",
    "    rank = comm.get().get_rank()\n",
    "    for k in w1:\n",
    "        #Crypten strangely only supports enc + plain but does not support the other way round (plain + enc)\n",
    "        if rank == WORKER1:\n",
    "            w1[k] = w1[k] + w2[k]\n",
    "        else:\n",
    "            w2[k] = w2[k] + w1[k]\n",
    "    #4. restore weights to basic model\n",
    "    if rank == WORKER1:\n",
    "        private_model.load_state_dict(w1)\n",
    "    elif rank == WORKER2:\n",
    "        private_model.load_state_dict(w2)\n",
    "    #5. inference\n",
    "    private_model.eval()\n",
    "    output_enc = private_model(user,feature)\n",
    "    crypten.print(output_enc.get_plain_text())\n",
    "    #Sanity check the model weights\n",
    "    # private_model.decrypt()\n",
    "    # print(private_model.state_dict())\n",
    "model_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO\\n1. complete this poc and confirm things are right\\n2. try deploy this in two separate machines\\n3. (see if ok) Modify PyGrid to give teh  encrypted tensors directly so even pygrid no need see the data?\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TODO\n",
    "1. complete this poc and confirm things are right\n",
    "2. try deploy this in two separate machines\n",
    "3. (see if ok) Modify PyGrid to give teh  encrypted tensors directly so even pygrid no need see the data?\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "694cb5ecd12f722d95921d5c5a312ddba03d00263a951b715d8b83b38cc41a70"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('crypten': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
